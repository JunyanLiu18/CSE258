{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.  threshold at 2 accuracy = 0.6531\n",
    "\n",
    "Q2. threshold at 1.5 accuracy =  0.659\n",
    "\n",
    "Q3. Jaccard threshold at 0.011 accuracy = 0.6187\n",
    "\n",
    "Q4. Jaccard threshold at 0.008 with popularity threshold at 1.4747 accuracy = 0.67075\n",
    "\n",
    "Q5. Kaggle user name: Junyan Liu\n",
    "\n",
    "Q9. lambda = 1 MSE =  1.4907800691966389\n",
    "\n",
    "Q10. largest user biases (0.00040413237874470305, 'u92864068')\n",
    "       \n",
    "       smallest user biases (-0.0015796730337471908, 'u11591742')\n",
    "       \n",
    "       largest book biases (0.0008292191795822705, 'b76915592')\n",
    "       \n",
    "       smallest book biases (-0.0002721486787445039, 'b57299824')\n",
    "\n",
    "Q11. lambda = 0.00008 MSE =  1.112277594252111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import csv\n",
    "\n",
    "path = \"/Users/apple/Desktop/CSE258/HW3/assignment1/train_Interactions.csv.gz\"\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')\n",
    "\n",
    "dataset = []\n",
    "books = set()\n",
    "userRatings = defaultdict(set)\n",
    "userReadings = defaultdict(set)\n",
    "bookUsersT = defaultdict(set)\n",
    "validSet = []\n",
    "for user, book, r in readCSV(path):\n",
    "    r = int(r)\n",
    "    books.add(book)\n",
    "    userRatings[user].add(r)\n",
    "    userReadings[user].add(book)\n",
    "    dataset.append([user, book, r])\n",
    "train = dataset[:190000]\n",
    "valid = dataset[190000:]\n",
    "validR = dataset[190000:]\n",
    "\n",
    "correct = 0\n",
    "users = set()\n",
    "allRatings = []\n",
    "userRatings = defaultdict(set)\n",
    "bookRatings = defaultdict(set)\n",
    "userBooks = defaultdict(set)\n",
    "bookUsers = defaultdict(set)\n",
    "for item in train:\n",
    "    u, b, r = item[0], item[1], item[2]\n",
    "    userBooks[u].add(b)\n",
    "    bookUsers[b].add(u)\n",
    "    allRatings.append(r)\n",
    "    userRatings[u].add(r)\n",
    "    bookRatings[b].add(r)\n",
    "    \n",
    "print(len(bookRatings[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "negValidSet = []\n",
    "for item in valid:\n",
    "    u = item[0]\n",
    "    b = random.choice(tuple(books))\n",
    "    while b in userBooks[item[0]]:\n",
    "        b = random.choice(tuple(books))\n",
    "    negValidSet.append([u, b, -1])\n",
    "valid = valid + negValidSet\n",
    "random.shuffle(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 2  0.6479\n",
      "threshold 1.5  0.6501\n"
     ]
    }
   ],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(path):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "correct = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break\n",
    "        \n",
    "for i in range(len(valid)):\n",
    "    if (valid[i][1] in return1 and valid[i][2] > -1) or (valid[i][1] not in return1 and valid[i][2] == -1) :\n",
    "            correct = correct + 1\n",
    "accuracy = correct/len(valid) \n",
    "print(\"threshold 2 \",accuracy)\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "correct = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/1.5: break\n",
    "for i in range(len(valid)):\n",
    "    if (valid[i][1] in return1 and valid[i][2] > -1) or (valid[i][1] not in return1 and valid[i][2] == -1) :\n",
    "            correct = correct + 1\n",
    "accuracy = correct/len(valid) \n",
    "print(\"threshold 1.5 \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard performance  0.62115\n"
     ]
    }
   ],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "predictionsJaccard = [] \n",
    "thresholdJaccard = 0.011\n",
    "\n",
    "correct = 0\n",
    "def mostSimilar(u, b):\n",
    "    for b2 in userBooks[u]:\n",
    "        if b == b2:\n",
    "            return 1\n",
    "        sim = Jaccard(bookUsers[b], bookUsers[b2])\n",
    "        if sim >= thresholdJaccard:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(valid)):\n",
    "    if (mostSimilar(valid[i][0], valid[i][1]) == 1 and valid[i][2]>=0) or (mostSimilar(valid[i][0], valid[i][1]) == 0 and valid[i][2] == -1):\n",
    "        correct = correct + 1\n",
    "accuracy = correct / len(valid)\n",
    "print(\"Jaccard performance \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard with popularity  0.5688\n"
     ]
    }
   ],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(path):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return2 = set()\n",
    "correct = 0\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return2.add(i)\n",
    "    if count > int(totalRead/1.4747): break\n",
    "        \n",
    "thresholdJaccard = 0.0425\n",
    "def mostSimilar(u, b):\n",
    "    for b2 in userBooks[u]:\n",
    "        if b == b2:\n",
    "            return 1\n",
    "        sim1 = Jaccard(bookUsers[b], bookUsers[b2])\n",
    "        for u2 in bookUsers[b]:\n",
    "            sim2 = Jaccard(userBooks[u], userBooks[u2])\n",
    "            if sim1 + sim2 >= thresholdJaccard:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(valid)):\n",
    "    if ((valid[i][1] in return2 and mostSimilar(valid[i][0], valid[i][1]) == 1) and valid[i][2] > -1) or ( not(valid[i][1]  in return2 and mostSimilar(valid[i][0], valid[i][1]) == 1) and valid[i][2] == -1):\n",
    "        correct = correct + 1\n",
    "accuracy = correct/len(valid)\n",
    "print(\"Jaccard with popularity \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.6712 0.04\n",
    "0.043 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "p = open('predictions_Read.txt', 'w') \n",
    "for i in open(\"/Users/apple/Desktop/CSE258/HW3/assignment1/pairs_Read.txt\"):\n",
    "    if i.startswith(\"userID\"):\n",
    "        p.write(i)\n",
    "        continue\n",
    "    u, b = i.strip().split('-')\n",
    "    if (b in return2 and mostSimilar(u, b) == 1):\n",
    "        s = str(u) + '-' + str(b)+',1\\n'\n",
    "        p.write(s)\n",
    "    else:\n",
    "        s = str(u) + '-' + str(b)+',0\\n'\n",
    "        p.write(s)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for user, book, r in readCSV(path):\n",
    "    r = int(r)\n",
    "    dataset.append([user, book, r])\n",
    "\n",
    "train = dataset[:190000]\n",
    "validR = dataset[190000:]\n",
    "\n",
    "userBooks = defaultdict(set)\n",
    "bookUsers = defaultdict(set)\n",
    "userRatings = defaultdict(set)\n",
    "bookRatings = defaultdict(set)\n",
    "for item in train:\n",
    "    u, b, r = item[0], item[1], item[2]\n",
    "    userBooks[u].add(b)\n",
    "    bookUsers[b].add(u)\n",
    "    userRatings[u].add(r)\n",
    "    bookRatings[b].add(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n",
    "def prediction(user, item):\n",
    "    if user not in userBiases:\n",
    "        return alpha + itemBiases[item] + inner(userGamma[user], itemGamma[item])\n",
    "    if item not in itemBiases:\n",
    "        return alpha + userBiases[user] + inner(userGamma[user], itemGamma[item])\n",
    "    if user not in userBiases and item not in itemBiases:\n",
    "        return alpha + inner(userGamma[user], itemGamma[item])\n",
    "    return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#simple\n",
    "def prediction(user, item):\n",
    "    if user not in userBiases:\n",
    "        return alpha + itemBiases[item]\n",
    "    if item not in itemBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    if user not in userBiases and item not in itemBiases:\n",
    "        return alpha\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#simple\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:usersN+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+usersN:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    global userGamma\n",
    "    global itemGamma\n",
    "    index = 0\n",
    "    alpha = theta[index]\n",
    "    index += 1\n",
    "    userBiases = dict(zip(users, theta[index:usersN+index]))\n",
    "    index += usersN\n",
    "    itemBiases = dict(zip(items, theta[index:index + itemsN]))\n",
    "    index += itemsN\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index:index + K]\n",
    "    for i in items:\n",
    "        itemGamma[i] = theta[index:index + K]\n",
    "        index += K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n",
    "def inner(x, y):\n",
    "    return sum([a*b for a,b in zip(x,y)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#simple \n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in train]\n",
    "    cost = MSE(predictions, labels)\n",
    "#     print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in train]\n",
    "    cost = MSE(predictions, labels)\n",
    "    #print(\"MSE test = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*userGamma[u][k]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*itemGamma[i][k]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#simple\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(train)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in train:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d[2]\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(train)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dItemGamma = {}\n",
    "    for u in userRatings:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for b in bookRatings:\n",
    "        dItemGamma[b] = [0.0 for k in range(K)]\n",
    "    for d in train:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d[2]\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2/N*itemGamma[i][k]*diff\n",
    "            dItemGamma[i][k] += 2/N*userGamma[u][k]*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2*lamb*userGamma[u][k]        \n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "        for k in range(K):\n",
    "            dItemGamma[i][k] += 2*lamb*itemGamma[i][k]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for i in items:\n",
    "        dtheta += dItemGamma[i]\n",
    "    return numpy.array(dtheta) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#simple\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "globalAverage = float(sum(allRatings)) / len(allRatings)\n",
    "userAverage = {}\n",
    "bookAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = float(sum(userRatings[u])) / len(userRatings[u])\n",
    "for b in bookRatings:\n",
    "    bookAverage[b] = float(sum(bookRatings[b])) / len(bookRatings[b])\n",
    "    \n",
    "N = len(train)\n",
    "usersN = len(userRatings)\n",
    "itemsN = len(bookRatings)\n",
    "users = list(userRatings.keys())\n",
    "items = list(bookRatings.keys())\n",
    "alpha = globalAverage\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "labels = [x[2] for x in train]\n",
    "\n",
    "theta = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(usersN+itemsN), derivative, args = (labels, 0.00001638))\n",
    "predictionsRatings = []\n",
    "labels = [x[2] for x in validR]    \n",
    "for l in validR:\n",
    "    u,b = l[0], l[1]\n",
    "    predictionsRatings.append(prediction(u, b))\n",
    "print(\"MSE = \", MSE(predictionsRatings, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'b21479253'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-6c268498cd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpredictionsRatings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionsRatings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-148ded83498b>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(user, item)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitemBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemBiases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muserBiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muserBiases\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemBiases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemGamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b21479253'"
     ]
    }
   ],
   "source": [
    "#complete\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "userGamma = {}\n",
    "itemGamma = {}\n",
    "K = 0\n",
    "globalAverage = float(sum(allRatings)) / len(allRatings)\n",
    "userAverage = {}\n",
    "bookAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = float(sum(userRatings[u])) / len(userRatings[u])\n",
    "for b in bookRatings:\n",
    "    bookAverage[b] = float(sum(bookRatings[b])) / len(bookRatings[b])\n",
    "    \n",
    "for u in userRatings:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "for b in bookRatings:\n",
    "    itemGamma[b] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "\n",
    "N = len(train)\n",
    "usersN = len(userRatings)\n",
    "itemsN = len(bookRatings)\n",
    "users = list(userRatings.keys())\n",
    "items = list(bookRatings.keys())\n",
    "alpha = globalAverage\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "labels = [x[2] for x in train]\n",
    "\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + # Initialize alpha\n",
    "                                   [0.0]*(usersN+itemsN) + # Initialize beta\n",
    "                                   [random.random() * 0.1 - 0.05 for k in range(K*(usersN+itemsN))], # Gamma\n",
    "                             derivative, args = (labels, 0.000009))\n",
    "\n",
    "predictionsRatings = []\n",
    "labels = [x[2] for x in validR]    \n",
    "for l in validR:\n",
    "    u,b = l[0], l[1]\n",
    "    predictionsRatings.append(prediction(u, b))\n",
    "print(\"MSE = \", MSE(predictionsRatings, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-63-ad0b08fd9975>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-63-ad0b08fd9975>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    MSE =  1.3981046685109149 0.001\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MSE =  1.3981046685109149 0.001\n",
    "\n",
    "0.0000\n",
    "0.00001  MSE =  1.1103306595248756\n",
    "0.000009 MSE =  1.1111025838530086\n",
    "\n",
    "0.0001 MSE =  1.177339418316401\n",
    "0.000001 MSE =  1.1259275772649437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = open('predictions_Ratings.txt', 'w') \n",
    "total = 0\n",
    "for i in open(\"/Users/apple/Desktop/CSE258/HW3/assignment1/pairs_Rating.txt\"):\n",
    "    if i.startswith(\"userID\"):\n",
    "        p.write(i)\n",
    "        continue\n",
    "    u, b = i.strip().split('-')\n",
    "    p.write(u + '-' + b + ',' + str(prediction(u, b)) + '\\n')\n",
    "    total = total + 1\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest user biases (1.189854343687313, 'u81539151')\n",
      "smallest user biases (-3.46140076316382, 'u76571258')\n",
      "largest book biases (1.0729518667954556, 'b19925500')\n",
      "smallest book biases (-1.392093899231559, 'b84091840')\n"
     ]
    }
   ],
   "source": [
    "max_user = max(zip(userBiases.values(), userBiases.keys()))\n",
    "min_user = min(zip(userBiases.values(), userBiases.keys()))\n",
    "max_book = max(zip(itemBiases.values(), itemBiases.keys()))\n",
    "min_book = min(zip(itemBiases.values(), itemBiases.keys()))\n",
    "print(\"largest user biases\",max_user) \n",
    "print(\"smallest user biases\",min_user)\n",
    "print(\"largest book biases\",max_book)\n",
    "print(\"smallest book biases\",min_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE =  1.108031456731227 0.0000164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE =  1.1080406170548083 0.00001631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE =  1.1080445762308229 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE =  1.1080405294805926  00001638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
